---
layout: layouts/guide.njk
title: 正規分布を理解し，分布に当てはめる
order : 7
tags: stat
---

# 7 正規分布を理解し，分布に当てはめる

## 7.1 今までの流れ

前回までで，母集団の身長の分布は$µ$=母平均，$σ^2$=母分散<small>(これは$σ$=母標準偏差とすることと同じ)</small>を代入した正規分布(これを$N(μ,σ^2)$で表します)であると考えることができました．

このことの意義をもう一度考えてみます．今や母集団の分布は$N(μ,σ^2)$そのものなので，分布を決めるのは，母平均$μ$と母分散$σ^2$の2つだけです．つまり，平均と分散の2つの情報だけを知れば，あらゆるa,bについての\\( P(a \leqq x \leqq b ) \\)を，f(x)を積分することで求められるのです．

これは，数式を当てはめなければ考えられないことです．分布を単に，

\\( P(a \leqq x \leqq b ) = \frac {a \leqq x \leqq b となるxの数} {母集団の要素数} \\) 

と捉えてしまっては，分布とは無限の情報の集まりになります．あらゆるa,bについて，$a \leqq x \leqq b$となるxの数を知る必要があるからです．一方，正規分布という構造を当てはめたことで，母集団の分布を決めるために知るべきことは，母平均$μ$と母分散$σ^2$だけになりました．つまり，サンプルから母集団の分布を推定するというとき，今までは無限の情報を推定しなければいけなかったのが，母平均と母分散という二つの母パラメータを推定するだけで良くなったのです．

ここで母パラメータという言葉を使うのは妥当です．なぜなら，μとσは正規分布f(x)に含まれるパラメータですし，母平均と母分散によって，$μ$と$σ^2$の値は決まるからです．このように，母集団の分布の形を決めるパラメータのことを，**母パラメータ**とか単に**パラメータ**とか**母数**といいます．例えば，正規分布の場合は，母平均$μ$と母分散$σ^2$が母パラメータです．この用語を使うと，サンプルから母パラメータを推定する際の誤差を定量化するのが今後の目標になります．

## 7.2 

母集団から1人ランダムサンプリングしたとき，その人の身長がXcmとなる確率は，その母集団の平均をμ，分散を$σ^2$とする正規分布$N(μ,σ^2)$で与えられます．この事実を「Xは正規分布$N(μ,σ^2)$に従う」とか「Xは正規分布$N(μ,σ^2)$で生成される」と言い， $X \sim N(μ,σ^2)$ で表します．

例えば，母集団が正規分布と見なせて，母平均=0，母分散=1の場合，そこからランダムサンプルした$X$は$X \sim N(0,1)$となるわけです．$N(0,1)$は**標準正規分布**と呼ばれる最も重要な正規分布です．

一般的に，$X$のように確率に従って，いろいろな値をとる変数を**確率変数**といいます．そして確率変数が従う確率を定める関数が**確率分布**です．つまり，**確率変数は確率分布によって，ある値となる確率が決められている**のです．この例ではサンプルの身長Xcmが確率変数で，正規分布$N(μ,σ^2)$が確率分布です．

<div class="leading-5 text-sm pt-2">母集団の身長データは確定したものであり，確率変数ではないことに注意してください．一人一人の身長は決まったものでランダムに動くことはありません．そこからランダムサンプリングすることがサンプルの身長Xを確率変数としています．</div>

## 7.3 

他の確率変数の例として，最も簡単なものはコイン投げです．コイン投げの結果をXとしましょう．ただし，オモテをX=1，ウラをX=0で表します．このとき，Xは確率変数であり，Xが従う確率分布は以下のようにヒストグラムで表せます．右は公平なコインの場合，左はウラが出やすいコインの場合です．

<img src="https://www.blue271828.com/img/terms/Bernoulli_distribution/pmf.svg" alt="" srcset="" class="mr-0 ml-auto my-4" width="350px" >

Xの確率分布をヒストグラムで表せるのはXが0,1の2つの値しか取らないからです．Xの確率分布は**ベルヌーイ分布**と呼ばれます．このことをまとめて「コイン投げを1回して出る目Xはベルヌーイ分布に従う確率変数である」と言います．言葉は難しく聞こえますが，言っていることは難しくありません．

- 確率変数は施行のたびにある確率に従って色々な値をとる．
- 確率分布はその確率を記述している．

ということさえ理解できれば大丈夫です．オモテが出る確率をpとして，ベルヌーイ分布を式で表せば次のようになります．

$$P(X=1)=p,P(X=0)=1-p$$

## 7.3 

ベルヌーイ分布は簡単な例過ぎて逆に分かりづらいかもしれません．別の例としては，n回コインを投げたときにオモテが出る回数Xを考えることができます．これもコインをn回投げるごとに，n/2回でたり，1回しかでなかったり，と色々な値をとるので，確率変数です．一般に1回コインを投げてオモテが出る確率がpなら，n回投げた時のオモテの回数X=kとなる確率$P(X=k)$は，

$$P(X=k) = {}_n \mathrm{ C }_k p^{k} (1-p)^{n-k}$$

で与えられるので，これが確率分布になります．確率分布とは，確率変数がある値になる確率を定める関数であったことを思い出しましょう．この確率分布を**二項分布**といいます．

二項分布はベルヌーイ分布の一般系です．実際，n=1とすればベルヌーイ分布に一致します．最後に$n=12,p=0.5$の二項分布(公平なコインを12回投げた時オモテが出る回数の分布)の図を載せましょう．

<img src="https://i.stack.imgur.com/cifQJ.jpg" alt="" srcset=""  url="https://riptutorial.com/r/example/26152/binomial-distribution" class="mr-0 ml-auto my-4" width="350px" >


## 7.4 

一般的には，コイン投げやサイコロ投げのように飛び飛びの値しかとらない確率変数を**離散**的といい，身長や体重のように無限にいろいろな値を取りうる確率変数を**連続**的といいます．この2つのタイプの確率変数が従う確率分布の違いは一様分布を考えるとよく分かります．

公平なサイコロを1回投げて出る目Xを考えます．Xは1,2,3,4,5,6の値をとる離散的な確率変数であり，**離散一様分布**に従います．離散一様分布は式で表すと次のとおりです．

$$P(X=k)=\frac{1}{6} \hspace{10pt} (1 \leqq k \leqq 6)$$

<img src="/img/stats/サイコロ投げの分布.png" alt="" srcset=""  url="https://riptutorial.com/r/example/26152/binomial-distribution" class="mr-0 ml-auto my-4" width="350px" >

一般的に1~Nまでの値をとる場合には，

$$P(X=k)=\frac{1}{N} \hspace{10pt} (1 \leqq k \leqq N)$$

となります．

一方，その確率分布をする母集団からランダムに1つ選ぶと，1~6までの実数が等確率で出てくるような確率分布を考えます．この場合，でた値xは1~6までの実数，つまり連続的な値をとるので，身長の場合と同じく，xがぴったり1になる確率，などを考えることはできません．そこで，$a \leqq x \leqq b$となる確率$P(a \leqq x \leqq b)$は，

$$f(x) = \frac{1}{5} \hspace{10pt} (1 \leqq x \leqq 6)$$

を用いて，

$$P(x)=\int_a^b f(x) dx$$

で求められます．これは**一様分布**と呼ばれます．一般的にa~bまでが等確率で出る場合には，

$$f(x) = \frac{1}{b-a} \hspace{10pt} (a \leqq x \leqq b)$$

となります．ただし，$a \leqq x \leqq b$以外のときは$f(x)=0$．

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Uniform_Distribution_PDF_SVG.svg/1200px-Uniform_Distribution_PDF_SVG.svg.png" alt="" srcset=""  url="https://en.wikipedia.org/wiki/Continuous_uniform_distribution" class="mr-0 ml-auto my-4" width="350px" >


## 7.5

以上から分かる通り，離散的な確率変数の場合，確率分布はX=kとなる確率を直接的に関数で表します．このような関数を**確率質量関数**といいます．

ベルヌーイ分布 : $P(X=1)=p,P(X=0)=1-p$
二項分布 : $P(X=k) = {}_n \mathrm{ C }_k p^{k} (1-p)^{n-k}$
離散一様分布 : $P(X=k)=\frac{1}{N} \hspace{10pt} (1 \leqq k \leqq N)$

は全て確率質量関数です．

一方で，連続的な確率変数の場合は，確率分布は直接的にX=kとなる確率を表すことはできない(X=kとなる確率は0)なので，関数f(x)を積分することで$P(a \leqq x \leqq b)$を表しました．f(x)は一般的には**確率密度関数**と呼ばれます．

正規分布：$f(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{\frac{-(x-\mu)^2}{2\sigma}}$
一様分布：$f(x) = \frac{1}{b-a} \hspace{10pt} (a \leqq x \leqq b)$

は全て確率密度関数です．<small>(一様分布と$P(a \leqq x \leqq b)$で同じ記号a,bを使っているのがややこしいですが，これらのa,bは同じ記号を使っているだけの別物です．分かりづらければ，例えば一様分布のaをcにbをdに変えてもいいでしょう．)</small>

イメージとしては密度を足し合わせることで質量になるように，確率密度関数を積分することで，Xがある値となる確率である値を表すことができる，つまり，確率質量関数と同じものを表すことができるようになるのです．

これらの分布以外にも色々な分布がありますが，全ての確率分布はギャンブルから生まれる，つまり，コイン投げ(ベルヌーイ分布や二項分布など)とサイコロ投げ(一様分布)から導くことができるといっても過言ではありません．しかし王様は正規分布です．詳しい話は10以降で話します．

## 7.6

色々な例を通じて，確率変数と確率分布に馴染めたところで，本題に戻ります．N人を正規分布$N(μ,σ^2)$からランダムサンプリングすることを考えましょう．このとき，k人目の身長を$X_k$とすると，$X_k \sim N(μ, σ^2)$です．

そしてN個の確率変数$X_k \hspace{3pt} (1 \leqq k \leqq N) $はそれぞれ**独立**です．独立とは，それぞれの$X$の値は他の$X$の値に影響されることなく，$N(μ,σ^2)$で定まる確率に従って生じるということです．これは，例えば3人目にサンプリングした人の身長$X_3$は$X_1$や$X_{N-1}$の値がどうであろうと関係なく，$N(μ,σ^2)$で定められる確率である値となることを考えれば，納得できると思います．この独立の概念は非常に重要なのですが，このシリーズでは特別言及しない限り，それぞれの確率変数は独立であると考えてよいです．

サンプル平均 $\overline{X}$は，

$$
\overline{X} = \frac{1}{N} \sum_{k=1}^{N} X_k
$$

で求められます．サンプル平均$ \overline{X}$のように，確率変数 $X_1,X_2 \cdots X_N$から計算される値のことを**統計量**といいます．

サンプル平均$ \overline{X}$と母平均$µ$については$E[\overline{X}] = µ$が成り立つのでした．つまり，サンプル平均は母平均の普遍統計量です．

他の統計量として，

$$
U^2 =\frac{1}{N-1} \sum_{k=1}^N (X_k - \overline {X})^2
$$

で定義される不偏分散$U^2$があります．普遍という名前の通り，母分散$σ^2$とは$E[U^2]=σ^2$の関係が成り立ちます．一方，サンプル分散$$S^2 =\frac{1}{N} \sum_{k=1}^N (X_k - \overline {X})^2$$も統計量ですが，これは$E[S^2]=\frac{N-1}{N}σ^2$であり，バイアスがあります．つまり，サンプル分散から母分散を推定しようとすると，系統誤差が生じてしまいます．

今後使う統計量は，サンプル平均$ \overline{X}$と不偏分散$U^2$の2つだけです．

サンプル分散$S^2$はサンプル自体の分散を求めるのには使えますが，知りたいのはサンプル自体の分散ではなく母分散です．現実世界で得られるもののほとんどはサンプルですが，知りたいのは母集団に関する情報です．サンプル自体には興味はないので，サンプルについて知れるサンプル分散ではなく，$E[U^2]=σ^2$を満たす不偏分散を使うことになります．

なぜ分母をN-1とすると，期待値が母分散と一致するのかについて[こちら](https://manabitimes.jp/math/1035)を参照してください．

## 7.7

ここで，正規分布には次の性質があります．

<div class="my-8">

A:和に関する再生性

確率変数X,Yが独立で
    $X \sim N(\mu_1,\sigma_1^{2})$
    $Y \sim N(\mu_2,\sigma_2^{2})$
のとき，
    $X + Y \sim N(\mu_1 + \mu_2, \sigma_1^{2} + \sigma_2^{2})$
</div>

<div class="my-8">B:定数倍に関する再生性

確率変数Xが
 $X \sim N(\mu,\sigma^{2})$
のとき，
 $aX + b \sim N(a\mu + b,a^2\sigma^{2})$
</div>

<div class="my-8">C.標準正規分布

確率変数Xが
 $X \sim N(\mu,\sigma^{2})$
のとき，
 $\frac{X-\mu}{\sigma} \sim N(0,1)$
このように，Xを $\frac{X-\mu}{\sigma}$ に変換することを標準化するという．
</div>

証明はいずれも[このサイト](https://risalc.info/src/st-normal-distribution-summary.html#rep)を参照してください．{.pb-10}

## 7.8

事実A.B.から $X_k \sim N(μ, σ)$なら，

$$ \overline{X} = \frac{1}{N} \sum_{k=1}^{N} X_k \sim N(\mu,\frac{\sigma^{2}}{N}) $$

を示せます．<small>(この証明は，A.B.を使えば簡単に示せるので，わからないければぜひ確認してください．証明は[同じサイト](https://risalc.info/src/st-normal-distribution-summary.html#rep:~:text=%E8%A8%BC%E6%98%8E%E3%82%92%E8%A6%8B%E3%82%8B-,%E6%A8%99%E6%9C%AC%E5%B9%B3%E5%9D%87%E3%81%AE%E6%AD%A3%E8%A6%8F%E5%88%86%E5%B8%83,-%E6%AD%A3%E8%A6%8F%E5%88%86%E5%B8%83)にあります．)</small>

これは正規分布からN個サンプルをとることを繰り返して，サンプル平均の分布を作っていくと

- サンプル平均もまた，正規分布に従うこと
- サンプル平均の平均は，母平均と一致すること
- 分散は各サンプルの1/Nとなること

を表しています．これは4.8において，集団Qからサンプルサイズを色々変えてサンプル平均の分布を調べた結果と一致しています．



<div class="mx-auto my-8 text-sm" style="width: 450px">
<span class="text-xl">結果1:</span>
<div class="pb-1">集団Qからの，あるサンプルの分布．サンプルサイズ$N=100$．分散は$18.79cm^2$</div>
<img src="/img/stats/サンプルサイズ100-2.png" alt="" srcset="" class="pb-3">
<div>N=100のサンプルをたくさん集めてサンプル平均の分布をつくったもの．正規分布している．平均は母平均と一致し，分散は$0.018cm^2$で，それぞれのサンプルの1/100倍になっていることが分かる．</div>
<img src="/img/stats/サンプル平均の平均N=100.png"  >
</div>


<div class="text-sm mx-auto pt-10 pb-4" style="width: 450px">
<span class="text-xl">結果2:</span>
<div>サンプルサイズNのサンプルのサンプル平均の分布．Nがk倍になると分散は1/k倍になっている．</div>
<div class="overflow-y-scroll h-96" style="height: 600px; " class="pb-4">
<img src="/img/stats/サンプル平均の平均N=100.png"  >
<img src="/img/stats/サンプル平均の平均N=200.png"  >
<img src="/img/stats/サンプル平均の平均N=400.png"  >
<img src="/img/stats/サンプル平均の平均N=1000.png"  >
</div>
</div>

サンプルサイズNが大きいほど散らばりが小さくなることは4.8の段階で分かりましたが，今や正規分布を当てはめたことで，分散$σ^2$は1/N倍に，散らばり$σ$は$\sqrt{\frac{1}{N}}$倍になることが分かります．正規分布の散らばり=山の幅はσ=標準偏差で決まっていたことを思い出しましょう．忘れた人は[このgeogebraのアプリ]で確認してください．

サンプル平均の標準偏差のことを<b>標準誤差</b>と言います．正規分布を導入することで，サンプル平均が平均的にどれだけ母平均と離れるか(標準誤差)を定量的に評価することができるようになりました．