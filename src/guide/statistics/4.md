---
layout: layouts/guide.njk
tags: stat
title: ランダムサンプル，サンプルサイズ，誤差
order : 4
---

# 4 ランダムサンプル，サンプルサイズ，誤差

## 4.1 

2集団が同一であるとは，2集団のあらゆる性質の分布が等しいこと，と定義しました．では，実際にあらゆる性質，私たちが知ることのできる性質も，知り得ない性質も全てが等しいような2集団はどうやって作るのでしょうか．


<div class="text-sm my-4">逆に，もし2集団の分布が何かしらの点で異なる場合，例えば，身長の伸びを促進する遺伝子Gの分布が異なっていれば，薬の効果と思っていたものは，実はこの遺伝子Gの分布の差に起因していたことがありえ，集団の平均差が薬の効果とはいえなくなります．つまり「薬の効果といっているけど，薬を使った群は，遺伝子Gをたくさんもっている人が多いのだから，これが薬群の身長の伸びが良かった原因で，薬の効果が原因ではないかもしれないよね？」などと反論される可能性があります．</div>

## 4.2 ランダムサンプリング

その方法が<b>ランダムサンプリング</b>です．(<b>無作為抽出</b>とも言います．)

ランダムサンプリングとはその名の通り，集団からランダムに，サンプルをとってくることです．例えば6人の集団があります．彼ら1人1人に1~6の番号をふって，サイコロを1度投げ，出た目に対応する番号の人を選ぶことにすれば，それはランダムサンプリングになります．


## 4.3 <small>ランダムサンプルすると分布が一致することの説明</small>

ある母集団Qからランダムサンプリングでサンプルを作ることを考えます．例えばQの身長の分布が次のようだったとしましょう．

<img src="/img/stats/集団Qの身長分布.png" alt="" class="mr-0 ml-auto my-4" width="350px" >

このように母集団の分布や，母平均$µ$や母分散$σ^2$を実際に知るのは困難なのですが，説明のために値を知っているものとして話を進めます．

このとき，Qからランダムサンプリングすれば，例えば96-97cmの人がでる確率は分布から読み取れるように0.06=6%になります．であれば，100人サンプリングすると，96-97cmの人は<b>平均して</b>\\(0.06 \cdot 100 = 6\\)人選ばれることになります．これを全体の人数100で割って割合にすれば，0.06となってQと一致します．他の身長についても同様に考えると，母集団Qとサンプルに含まれる人数は<b>平均して</b>同じ割合になることが分かります．よって，身長の分布は<b>平均すると</b>一致します．

<stbl>平均して</stbl>同じになる，というのは，6%の確率で96-97cmが選ばれるからといって，100人選んでくれば常にちょうど6人が96-97cmとなるわけではないからです．これは公平なコインを100回投げても，必ずしもオモテがちょうど50回出ないことからも明らかでしょう．実際，集団Qから100人サンプリングした場合を5つ見てみると次のようになり，分布はQと一致しているように見えません．実際，どのサンプル平均$m$についても$m≠μ$です．<small>(母分散とサンプル分散の不一致については後々説明があります．)</small>

<div class="overflow-y-scroll h-96 mr-0 ml-auto my-4" style="height: 400px; width: 400px" class="pb-4">
<img src="/img/stats/サンプルサイズ100-1.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100-2.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100-3.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100-4.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100-5.png" alt="" srcset="">
</div>

ですが，サンプリングしてくる人の数(これを**サンプルサイズ**と言います)を増やすとどうでしょうか．つまり，母集団Qから抜き出す人数をもっと増やしていけば，サンプル中の96-97cmの割合は8%に近づいていきます．これは公平なコインをひたすらに投げていけば，出たオモテの割合が1/2に近づいていくことと同じです．

よって，ランダムサンプリングにした人数が十分多ければ，母集団Qとサンプルの身長の分布は一致すると見なせるはずです．実際，100万人サンプリングした場合を5つ見てみると次のようになり，分布・平均はQと常にほとんど一致していることが分かります．<small>(ここでも母分散とサンプル分散はやや不一致ですが，これも後々説明があります．)</small>

<div class="overflow-y-scroll h-96 mr-0 ml-auto my-4" style="height: 400px; width: 400px" class="pb-4">
<img src="/img/stats/サンプルサイズ100万.png"  >
<img src="/img/stats/サンプルサイズ100万-2.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100万-3.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100万-4.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100万-5.png" alt="" srcset="">
</div>


よって，十分大きいサンプルでは分布は一致し，$m=μ$なのです．ということは，最初に示した集団Qの分布や平均を知らなくても，そこから十分にたくさんランダムサンプルしたサンプルをみれば，母平均を推定することができることが分かります．


## 4.4 <small>ランダムサンプルするとすべての分布が一致する</small>

身長以外の性質の分布についても，全く同じ理屈でサンプルサイズが十分大きければ，母集団とサンプルで分布は一致します．私たちが知り得る性質も，知り得ない性質も，全ての性質の分布が一致するのです．つまり，母集団とサンプルは同一の集団とみなすことができます．

## 4.5 <small>複製する代わりにランダム割当をすればいい</small>

であれば，薬の効果を調べるために，ステップ2の複製は必要ありません．

<img src="/img/stats/5人の子供の集団ver.png" alt="" class="mr-0 ml-auto my-4" width="430px" >

そのかわりに，

1. 集団からランダムサンプリングして半分を抜き出す．
2. 抜き出した集団を薬群，残った集団をプラセボ群にする．<small>(もちろん逆でも可)</small>
{.pt-4}

という方法をとります．元の集団のサイズがとても大きければ，半分を取り出したものにも十分なサンプルサイズがあると見なせます．よって，元の集団と分割後の2つの集団は同一の集団です．この方法は，集団の構成員1人1人に1/2の確率で(つまりランダムに)薬を飲むのかプラセボを飲むのかを割り当てても同じことなので，ランダム割当とも呼ばれます．

<img src="/img/stats/ランダム割当.png" alt="" class="mr-0 ml-auto my-4" style="width: 400px;">

## 4.5 <small>母集団の代わりにランダムサンプルで集めたサンプルを調べればいい</small>

こうして考えると，もう１つの困難「母集団を集めることができない」も解消されることが分かります．母集団からランダムサンプリングして，十分なサンプルサイズをもつサンプルを作れば，そのサンプルは母集団と同一の集団と見なせるからです．

<img src="/img/stats/ランダム抽出.png" alt="" class="mr-0 ml-auto my-4" style="width: 400px;">

こうして2つの困難は次のように解決されます．

1. 母集団を集めること 
    \\(\rightarrow \\) 母集団からランダムサンプリングで十分なサンプルサイズのサンプルを作る(ランダム抽出)
2. 母集団を構成する1人1人を複製すること 
    \\(\rightarrow \\) ランダムサンプリングで集団を2分割する(ランダム割当)

## 4.6　<small>十分に大きなサンプルを使って薬の効果を求める方法</small>

これで実際に実行可能な実験の手順が分かりました．

1. 母集団からランダム抽出して，十分に大きいサンプルをつくる．
2. ランダム割当で薬群とプラセボ群に分ける．
3. 実験を行って，サンプルの差\\(m^D - m^P\\)を薬の効果と考える．

<img src="/img/stats/サンプルサイズが大きいとき.png" alt="" class="mx-auto mb-4 mt-10"  style="width: 400px;">

## 4.7　<small>サンプルサイズが小さいときに薬の効果について言えることは？</small>

これで複製や時間操作などの圧倒的困難から逃れて，理屈としては実行可能になりました．しかし，十分に大きいサンプルを作る，例えばサンプルを100万人集めて調べることも難しいことです．

確かにサンプルサイズが十分大きくなければ$m=μ$とはならないので，サンプルから薬の効果を完全に正確・確実に求めることはできないのですが，もっと現実的な，小さいサンプルのときには，ただ$m \neq μ$ということしか分からないのでしょうか？そんなことはないはずです．

## 4.8 <small></small>

そこで，もう一度集団QからサンプルサイズN=100のサンプルを，いくつか取り出したものを見てみます．

<div class="overflow-y-scroll h-96 mr-0 ml-auto my-4" style="height: 400px; width: 400px" class="pb-4">
<img src="/img/stats/サンプルサイズ100-1.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100-2.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100-3.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100-4.png" alt="" srcset="">
<img src="/img/stats/サンプルサイズ100-5.png" alt="" srcset="">
</div>

分布は平均的にしか一致しないので，サンプル平均の値はバラバラですが，どのサンプル平均も母平均$µ=100.50$と近い値であることが分かります．

そこで，サンプル平均は母平均からどのくらい離れるものなのかを数字で知りたくなります．それを知るために

1. 集団Qから100人サンプルしたものを1万個つくる．
2. 1万個のサンプル平均についてのヒストグラムをつくる．

ということをやってみます．つまり，N=100のサンプルをたくさんとってきて，それぞれサンプル平均を計算し，その分布をヒストグラムに表して，真の母平均からの離れ具合を視覚化してみるのです．結果は次のようになります．

<img src="/img/stats/サンプル平均の平均N=100.png" alt="" class="mx-auto my-8" width="500px" >

ここから言えるのは次のことです．

1. サンプル平均の平均は母平均$µ=100.50$と一致している．
2. サンプル平均の分散は，一つ一つのサンプルの分散よりもずっと小さい．
{.pt-4}

## 4.8.1 <small>$E[m] = µ$であること</small>
1.については「サンプル平均の期待値は母平均と一致している」というふうにも言い換えられます．期待値とは直観的には，

- ランダムに選ばれたサンプル1つ1つから求められる値を
- たくさんのサンプルについて平均をとった値
{.pt-4}

のことです．この例では，

- サンプル平均はランダムに選ばれたサンプルから求められる値で，
- 1万個というたくさんのサンプルの平均値が100.50であり，
- これが母平均と一致している．
{.pt-4}

ことから，「サンプル平均の期待値は母平均と一致している」というふうにいえます．これを$E[m] = µ$で表しましょう．Eは期待値(Expected value)の頭文字です．期待値については4.10にも解説を書いたので，そちらも見てください．

## 4.8.2 <small>$Nが大きいほどV[m]は小さいこと</small>

次に2についてです．2は「サンプル平均の分散は，一つ一つのサンプルの分散よりもずっと小さい」でした．これは，サンプルサイズ100であるサンプル1つの分布と，サンプルサイズ100のサンプル平均の分布を比べてみるとよく分かります．

<div class="w-fit mx-auto my-8">
    サンプルサイズ100のあるサンプルの分布
    <img src="/img/stats/サンプルサイズ100-2.png" alt=""  width="500px">
</div>

<div class="w-fit mx-auto mb-4">
サンプルサイズ100のサンプル平均の分布
<img src="/img/stats/サンプル平均の平均N=100.png" alt=""  width="500px" >
</div>

前者の分散は約19なのに対して，後者の分散は約0.18です．グラフの横軸の範囲が違うことに注意しましょう．

サンプルサイズを変えて同様にサンプル平均の分布を作ってみると，さらに事態がはっきりします．例えば，サンプルサイズを200人にした場合で，サンプル平均の分布を調べてみます．つまり，

1. 集団Qから200人サンプルしたものを1万個つくる．
2. 1万個のサンプル平均についてのヒストグラムをつくる．

その結果は次のようになります．

<img src="/img/stats/サンプル平均の平均N=200.png" alt="" class="mx-auto my-4" width="500px" >

ここから言えるのは次のことです．

1. N=100の場合と同じく$E[m] = µ$
2. N=100よりも，分散が小さい．

1番目の事実は良いでしょう．サンプルサイズNによらず，サンプル平均は**平均して**母平均と一致しているのです．

それよりも2番目の事実です．ここから，サンプルサイズを大きくしていけば，分散が小さくなる，つまり，サンプル平均と母平均の誤差が平均して小さくなっていくことが予想できます．そして最終的に十分大きいサンプルでは，分散は0に近づいて，母平均からの散らばりを0と見なせるために，$m=µ$となるのでしょう．実際，サンプルサイズN=100,200,400,1000として，1万個サンプルをとり，サンプル平均の分布を作ったものは次のとおりです．ただし横軸の範囲は見やすいように揃えてあります．

<div class="overflow-y-scroll h-96 mr-0 ml-auto my-4" style="height: 600px; width: 560px" class="pb-4">
<img src="/img/stats/サンプル平均の平均N=100.png"  >
<img src="/img/stats/サンプル平均の平均N=200.png"  >
<img src="/img/stats/サンプル平均の平均N=400.png"  >
<img src="/img/stats/サンプル平均の平均N=1000.png"  >
</div>

## 4.9

以上から，サンプルと母集団の関係について次のことが言えます．ただし，サンプル平均の分散を$V[m]$で表しています．

- サンプル平均mと母平均µは一致しない．
- それゆえ，サンプルから計算される\\(m^D - m^P\\)は，母集団から計算される薬の真の効果$µ^D-µ^P$と一致しない．
- しかし，$E[m] = µ$より，$E[m^D - m^P] = µ^D-µ^P$なので，2つは平均的には一致している．
- そして，$V[m]$は，Nが大きくなるほど小さい．
- それゆえ，$V[m]=0$と見なせるほどNが大きいときには，$m^D - m^P = µ^D-µ^P$と見なせる．
- つまり，サンプルサイズNが十分大きければ，薬の効果は$m^D - m^P$で求められる．
{.pt-8 .pb-4}


現実的にはサンプルサイズNは$V[m]=0$と見なせるほど大きくはできません．それゆえ，真の値$µ^D-µ^P$そのものを知ろうとするのではなく，
サンプル平均の差$m^D - m^P$とのずれの量を評価する方法が必要になります．例えば，あるサンプルについて，$m^D - m^P= +5cm$となって，真の値とのずれは2cm以内，つまり，$3<µ^D-µ^P<7$ということさえ分かれば，十分に意思決定することできます．

## 4.10

これでサンプルサイズNが十分に大きくない場合の，実験の手順が分かりました．

1. 母集団からランダム抽出して，サンプルサイズNのサンプルをつくる．
2. ランダム割当でサンプルサイズN/2の薬群とプラセボ群に分ける．
3. 実験を行って，サンプルの差\\(m^D - m^P\\)から真の薬の効果\\(µ^D - µ^P\\)を推定し，それに誤差がどれだけあるかを考える．
{.py-4}

## 4.12

サンプルサイズが大きくないので，

- ランダム抽出において : 母集団とサンプルは平均的には一致するが，実際にできたサンプルと母集団には差がある．
- ランダム割当において : もとのサンプルと，薬群・プラセボ群は平均的には一致するが，実際にできたものには差がある．
{.py-4}

ことに注意する必要があります．つまり，ランダム抽出もランダム割当も**平均的に**同一の集団を作ることを保証してくれるだけなので，実際のサンプルではどうなっているかに注意を配る必要があります．

## 4.13

薬の効果を調べる実験を行うために残された問題は次の2つです．

1. サンプルサイズNをどう設定すればいいか．
2. サンプルサイズNのサンプルから推定した母集団についての情報に含まれる誤差を，定量的に評価するためにはどうすればいいか．
{.pt-4}

1点目については，もちろん，可能な限り多く集めるという手も1つですが，これは意思決定の方法としては貧弱です．サンプルは多ければ多いほど調べるのにコストがかかるので，必要もないのにたくさん集める必要はありません．誤差がある程度あっても意思決定に困らないことが分かっているなら，許容できる誤差をもとに，最小限必要になるサンプル数を事前に求めておき，コストとの兼ね合いからサンプル数を決めるのが良いでしょう．

2点目については，このシリーズの前半からの姿勢の変化を感じ取ってください．前半では正しい意思決定のために**完全に確実な方法**は何かということを理解しました．このような根本原理を理解することは非常に大切です．しかし，現実的には，完全に確実な方法など実行する必要がないのです．

例えば，真の値100.498023114だったとしましょう．このとき，大体100前後(例えば90~110に真の値があること)であることが分かれば十分な場合もあれば，100.5に近いこと(例えば100.45~100.55に真の値があること)まで知る必要がある場合もあります．例えば高速を運転しているときは，車の速度が大体100km/hであることが分かれば十分ですし，なにかの部品を作るときには正確に100.5cmに近いことを保証する必要があるかも知れません(もちろん，その場合でもぴったり100.498023114cmにする必要などありません)．このように状況に応じて，真の値から許容できる誤差が決まるため，**完全に確実な方法**である方法よりも，ニーズに合わせて低コストで実行可能な，**不確実だけど誤差がどれだけあるかは分かる方法**のほうが好ましいのです．

ということで，サンプル数を十分に集めて完全に確実に真の値を知る，という姿勢から，許容できる誤差とコストを定量的に評価して，適切なサンプルから真の値を推定するという姿勢にシフトしていきます．

誤差を定量的に求めるためには，今までラフに考えていた部分をもう少し厳密に正確に見ていく必要があります．その代表は分布です．

<hr class="my-8">


## 4.A 期待値について

期待値という概念は，長期的に賭けに参加したときの損得の計算に由来します．

例えば，コインのオモテ・ウラどちらが出るかを予想して，当たったら掛け金の3倍，外れたら掛け金没収というギャンブルがあります．掛け金100円なら当たったときは300円得られて，外れたときは0円得られます．

掛け金100円でこのゲームを延々とやり続けて，合計N回やったとしましょう．このとき，Nが十分大きいので，公平なコインであれば，N/2回当たって，N/2回外れるはずです．もちろん完全にピッタリN/2回というわけには行きませんが，Nが大きければほとんどN/2回と見なせるということです．これについては実験しているサイトがあるのでそちらを参照．

であれば，N回で得られるお金は合計$300\cdot \frac{1}{2} N + 0 \cdot \frac{1}{2} N =150N$円です．ゲーム一回あたりに換算，つまり平均をとると，150円となります．これがこのゲームの期待値です．つまり，一回やれば平均150円が得られて，掛け金は100円なので，平均して1回あたり50円の儲けになります．だからこのギャンブルはやるべきでしょう．

素朴には，あるギャンブルの期待値が掛け金を上回るのなら，それはやり続ければお金が増えるゲームなのでやるべき，ということになります．興味がある人は，期待値だけで判断することができない例を解説している面白いyoutubeの動画も見てみましょう．

## 4.B <small>普遍(unbiased)と精度(precision)について</small>

4.8において，サンプル平均の期待値は母平均と一致すること，つまり$E[m] = µ$を確認しました．

サンプル平均のように，サンプルから計算される値(一般には**統計量**といいますが，詳しい説明は後ほど)の期待値が，母集団についての何らかの値(一般には**母パラメータ**といいますが，それも後ほど)と一致するとき，その値を**普遍統計量**といいます．これらの用語を使うと，サンプル平均は母平均の普遍統計量だと言えます．

一方，これも詳しくは後ほどやりますが，サンプルの分散は母分散の普遍統計量ではありません．つまり$E[s^2] \neq σ^2$なのです．

普遍は英語ではunbiased，つまりバイアスがかかっていないという意味です．統計におけるバイアスを統計誤差ともいいます．普遍でない統計量から母パラメータを推定しようとする場合には，期待値が母パラメータと一致しないことから，ずれが常にあることになります．これは図でいうと，右の2つの状態です．的の真ん中が知りたい母パラメータで，サンプルをとるごとに，ダーツを投げられる(統計量から母パラメータを推定する)わけですが，真ん中からは平均してずれています．一方普遍(unbiased)であれば，平均的には真ん中に一致しています(左2つ)．

<img src="https://www.researchgate.net/profile/Anna-Karin-Hamberg/publication/297880023/figure/fig2/AS:669096064589835@1536536341243/Measures-of-accuracy-reported-as-bias-and-precision-reported-as-imprecision-of-model.png" alt="" srcset="" width="400px" class="mx-auto my-4">

平均的には真の値と一致しても，どれだけ散らばりがあるのかでpreciseかimpreciseかに分かれます．これは分散の別の表現と捉えてもいいでしょう．系統誤差と対比して偶然誤差と言う言葉もよく使われます．preciseであれば，散らばりは小さく，さらにunbiasedなら真の値を良く推定できることになります．しかし，preciseであっても，バイアスがあれば，ただ外れた値に揃うだけなので意味がありません．

ということは第一には普遍(unbiased)であることが重要です．だからこそ普遍統計量は重要なのです．では，普遍統計量がいくつもある場合には最も良いものをどう選べばいいでしょうか．もちろん精度(precision)が高いものを選べばいいですね．ということで，普遍統計量の中でも誤差が最も小さくなるようなものを最良普遍推定量といいます．例えばサンプル平均は最良普遍推定量であることが知られています．

ほとんど同じ概念として正確度(accuracy)があります．これはunbiasedと同じことです．つまりバイアスがなければ正確なのです．ちなみに，precisionの同義語としてはreliabilityが，accuracyの同義語としてはvalidityがあります．同じ意味をもつ異なる似た用語が多いので混乱しますが，ダーツの図で概念が理解できれば用語を覚える必要ありません．

<div class="hidden">


そして，サンプル薬群は

母集団からランダム抽出=>ランダム割当=>薬投与によってできた群ですが，
母集団を複製(ランダム割当に相当)=>薬投与=>母集団の薬群からのランダムサンプリング(ランダム抽出に相当)というふうに，母薬群からのランダムサンプルでできた群だと見ることもできることに注意しましょう．こう考えると，サンプル薬群は，母薬群からランダムサンプルでできた平均的には同じ集団なので，サンプル薬群の平均$m^D$から母薬群の平均$µ^D$を推定することができます．これは，集団Qの平均をサンプリングしたサンプルから推定できたことと全く同じことです．

サンプルプラセボ群についても同様に母プラセボ群からのランダムサンプルであると考えられるので，$m^P$から$µ^P$を推定できます．こうすれば，サンプルの差\\(m^D - m^P\\)と，真の薬の効果\\(µ^D - µ^P\\)の誤差を考えることも可能のように思えてきます．
</div>
